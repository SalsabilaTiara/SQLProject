{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing libraries and downloading data\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime \n",
    "\n",
    "# Download the required exchange rate file using the terminal command:\n",
    "# wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exchange_rate.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the CSV data first into a local `exchange_rate.csv` file\n",
    "import wget\n",
    "wget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here, you define the required entities and call the relevant\\nfunctions in the correct order to complete the project. Note that this\\nportion is not inside any function.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE STRUCTURE\n",
    "# Create the file banks_project.py in the path \\home\\project\\. Copy and paste the following code structure to the file:\n",
    "\n",
    "# Code for ETL operations on Country-GDP data\n",
    "\n",
    "# Importing the required libraries\n",
    "\n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing'''\n",
    "\n",
    "def extract(url, table_attribs):\n",
    "    ''' This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. '''\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform(df, csv_path):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_to_csv(df, output_path):\n",
    "    ''' This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.'''\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.'''\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "\n",
    "''' Here, you define the required entities and call the relevant\n",
    "functions in the correct order to complete the project. Note that this\n",
    "portion is not inside any function.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress generated warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1: Logging Function\n",
    "# This function accepts the message to be logged and enters it to the log file on a new line.\n",
    "# Log entries will be in the format: <timestamp> : <message>\n",
    "\n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing'''\n",
    "\n",
    "    timestamp_format = \"%Y-%h-%d-%H:%M:%S\" # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file,\"a\") as f:\n",
    "        f.write(timestamp + \" : \" + message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2: Extraction of Data\n",
    "\n",
    "def extract(url, table_attribs):\n",
    "    ''' This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. '''\n",
    "\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    df = pd.DataFrame(columns=table_attribs)\n",
    "\n",
    "    tables = soup.find_all(\"tbody\")\n",
    "    rows = tables[0].find_all(\"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        col = row.find_all(\"td\")\n",
    "        if len(col) != 0:\n",
    "            data_dict = {\"Name\": col[1].find_all(\"a\")[1][\"title\"],\n",
    "                         \"MC_USD_Billion\": float(col[2].contents[0][:-1])}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 3 : Transformation of Data\n",
    "\n",
    "def transform(df, csv_path):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "\n",
    "    # Read exchange rate CSV file\n",
    "    exchange_rate = pd.read_csv(csv_path)\n",
    "\n",
    "    # Convert to a dictionary with \"Currency\" as keys and \"Rate\" as values\n",
    "    exchange_rate = exchange_rate.set_index(\"Currency\").to_dict()[\"Rate\"]\n",
    "\n",
    "    # Add MC_GBP_Billion, MC_EUR_Billion, and MC_INR_Billion\n",
    "    # columns to dataframe. Round off to two decimals\n",
    "    df[\"MC_GBP_Billion\"] = [np.round(x * exchange_rate[\"GBP\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    df[\"MC_EUR_Billion\"] = [np.round(x * exchange_rate[\"EUR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    df[\"MC_INR_Billion\"] = [np.round(x * exchange_rate[\"INR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4: Loading to CSV\n",
    "\n",
    "\n",
    "def load_to_csv(df, output_path):\n",
    "    ''' This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.'''\n",
    "\n",
    "    df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 5: Loading to Database\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.'''\n",
    "\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 6: Function to Run Queries on Database\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING EXTRACT-TRANSFORM-LOAD PROCESS\n",
    "#Declaring known values\n",
    "\n",
    "url = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "csv_path = \"./exchange_rate.csv\"\n",
    "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
    "output_path = \"./Largest_banks_data.csv\"\n",
    "db_name = \"Banks.db\"\n",
    "table_name = \"Largest_banks\"\n",
    "log_file = \"./code_log.txt\"\n",
    "\n",
    "log_progress(\"Preliminaries complete. Initiating ETL process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name  MC_USD_Billion\n",
      "0                           JPMorgan Chase          432.92\n",
      "1                          Bank of America          231.52\n",
      "2  Industrial and Commercial Bank of China          194.56\n",
      "3               Agricultural Bank of China          160.68\n",
      "4                                HDFC Bank          157.91\n",
      "5                              Wells Fargo          155.87\n",
      "6                                     HSBC          148.90\n",
      "7                           Morgan Stanley          140.83\n",
      "8                  China Construction Bank          139.82\n",
      "9                            Bank of China          136.81\n"
     ]
    }
   ],
   "source": [
    "# Call extract() function\n",
    "\n",
    "df = extract(url, table_attribs)\n",
    "print(df)\n",
    "\n",
    "log_progress(\"Data extraction complete. Initiating Transformation process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                                     HSBC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n"
     ]
    }
   ],
   "source": [
    "# Call transform() function\n",
    "df = transform(df, csv_path)\n",
    "print(df)\n",
    "\n",
    "log_progress(\"Data transformation complete. Initiating Loading process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call load_to_csv()\n",
    "\n",
    "load_to_csv(df, output_path)\n",
    "\n",
    "log_progress(\"Data saved to CSV file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SQLite3 connection\n",
    "\n",
    "sql_connection = sqlite3.connect(db_name)\n",
    "\n",
    "log_progress(\"SQL Connection initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call load_to_db()\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "log_progress(\"Data loaded to Database as a table, Executing queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * from Largest_banks\n",
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                                     HSBC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n"
     ]
    }
   ],
   "source": [
    "# Call run_query()\n",
    "# Print the contents of the entire table\n",
    "\n",
    "\n",
    "query_statement = f\"SELECT * from {table_name}\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
      "   AVG(MC_GBP_Billion)\n",
      "0              151.987\n"
     ]
    }
   ],
   "source": [
    "# Call run_query()\n",
    "# Print the average market capitalization of all the banks in Billion GBP\n",
    "\n",
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Name from Largest_banks LIMIT 5\n",
      "                                      Name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    }
   ],
   "source": [
    "# Call run_query()\n",
    "# Print only the names of the top 5 banks\n",
    "\n",
    "\n",
    "query_statement = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress(\"Process Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close SQLite3 connection\n",
    "sql_connection.close()\n",
    "\n",
    "log_progress(\"Server Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-Feb-18-15:18:31 : Preliminaries complete. Initiating ETL process\n",
      "2025-Feb-18-15:19:53 : Data extraction complete. Initiating Transformation process\n",
      "2025-Feb-18-15:22:26 : Preliminaries complete. Initiating ETL process\n",
      "2025-Feb-18-15:22:27 : Data extraction complete. Initiating Transformation process\n",
      "2025-Feb-18-15:22:27 : Data transformation complete. Initiating Loading process\n",
      "2025-Feb-18-15:23:23 : Data saved to CSV file\n",
      "2025-Feb-18-15:23:39 : SQL Connection initiated\n",
      "2025-Feb-18-15:24:07 : Data loaded to Database as a table, Executing queries\n",
      "2025-Feb-18-15:25:25 : Process Complete\n",
      "2025-Feb-18-15:25:49 : Server Connection closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 7: Verify log entries\n",
    "# Upon successful completion of execution, you should see all the \n",
    "# relevant entries made in the log file in relation to the stages of code execution.\n",
    "\n",
    "\n",
    "with open(log_file, \"r\") as log:\n",
    "    LogContent = log.read()\n",
    "    print(LogContent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
